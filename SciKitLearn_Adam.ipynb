{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import seed\n",
    "import numpy as np\n",
    "seed(1)\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(2)\n",
    "\n",
    "import tensorflow as tf\n",
    "# from tensorflow.python.keras.optimizers import Fire\n",
    "from tensorflow.python.keras.optimizers import Adam\n",
    "from tensorflow.python.keras import backend as K\n",
    "from tensorflow.python.keras import optimizers\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the input data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preparing the input data\n",
    "\n",
    "#loading the MNIST dataset\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "#Separating into train and test (60000 train, 10000 test)\n",
    "(x_train, y_train0),(x_test, y_test0) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "#flattening the images (from 28x28 to 784)\n",
    "x_train = x_train.reshape(60000, 784)\n",
    "x_test = x_test.reshape(10000, 784)\n",
    "\n",
    "#we do not need to convert the outputs to one hot vectors.\n",
    "#Also, if we convert the output to one hot vectors, the _label_binarizer.y_type_ \n",
    "#    becomes multilabel and the out_activation_ becomes logistic\n",
    "#    Since keras and pytorch use softmax, we need to keep it like this\n",
    "# #converting the otputs (labels) into one hot vectors\n",
    "# lb = preprocessing.LabelBinarizer()\n",
    "# lb.fit(np.array([0,1,2,3,4,5,6,7,8,9]))\n",
    "# y_train = lb.transform(y_train0)\n",
    "# y_test = lb.transform(y_test0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the input parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining the input parameters\n",
    "BatchSize         = 500\n",
    "NeuronsLayer1     = 100\n",
    "NeuronsLayer2     = 100\n",
    "Epochs            = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model in SKLearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the net\n",
    "# Construct our model, # Construct our loss function and an Optimizer. \n",
    "\n",
    "#MLP regressor uses the square loss\n",
    "#MLP classifier uses the log loss function\n",
    "MLP_clf =  MLPClassifier( hidden_layer_sizes         = (NeuronsLayer1,NeuronsLayer2),\n",
    "                          activation                 = 'relu',#,'identity', 'tanh', 'relu'],\n",
    "                          solver                     = 'adam',\n",
    "                          alpha                      = 0.0         ,\n",
    "                          batch_size                 = BatchSize,\n",
    "                          max_iter                   = Epochs              ,\n",
    "                          random_state               = 1234,\n",
    "                          tol                        = -10.0 ,\n",
    "                          verbose                    = True,\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activation': 'relu',\n",
       " 'alpha': 0.0,\n",
       " 'batch_size': 500,\n",
       " 'beta_1': 0.9,\n",
       " 'beta_2': 0.999,\n",
       " 'early_stopping': False,\n",
       " 'epsilon': 1e-08,\n",
       " 'hidden_layer_sizes': (100, 100),\n",
       " 'learning_rate': 'constant',\n",
       " 'learning_rate_init': 0.001,\n",
       " 'max_iter': 100,\n",
       " 'momentum': 0.9,\n",
       " 'n_iter_no_change': 10,\n",
       " 'nesterovs_momentum': True,\n",
       " 'power_t': 0.5,\n",
       " 'random_state': 1234,\n",
       " 'shuffle': True,\n",
       " 'solver': 'adam',\n",
       " 'tol': -10.0,\n",
       " 'validation_fraction': 0.1,\n",
       " 'verbose': True,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Show aprameters of the network\n",
    "MLP_clf.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.57325389\n",
      "Iteration 2, loss = 0.21299496\n",
      "Iteration 3, loss = 0.15770762\n",
      "Iteration 4, loss = 0.12626270\n",
      "Iteration 5, loss = 0.10237293\n",
      "Iteration 6, loss = 0.08634479\n",
      "Iteration 7, loss = 0.07412249\n",
      "Iteration 8, loss = 0.06540337\n",
      "Iteration 9, loss = 0.05561397\n",
      "Iteration 10, loss = 0.04935638\n",
      "Iteration 11, loss = 0.04262858\n",
      "Iteration 12, loss = 0.03737120\n",
      "Iteration 13, loss = 0.03318029\n",
      "Iteration 14, loss = 0.02973333\n",
      "Iteration 15, loss = 0.02592448\n",
      "Iteration 16, loss = 0.02404487\n",
      "Iteration 17, loss = 0.01937777\n",
      "Iteration 18, loss = 0.01869876\n",
      "Iteration 19, loss = 0.01705470\n",
      "Iteration 20, loss = 0.01381812\n",
      "Iteration 21, loss = 0.01187036\n",
      "Iteration 22, loss = 0.01088985\n",
      "Iteration 23, loss = 0.01068537\n",
      "Iteration 24, loss = 0.00757951\n",
      "Iteration 25, loss = 0.00762695\n",
      "Iteration 26, loss = 0.00575214\n",
      "Iteration 27, loss = 0.00497791\n",
      "Iteration 28, loss = 0.00505738\n",
      "Iteration 29, loss = 0.00404529\n",
      "Iteration 30, loss = 0.00376933\n",
      "Iteration 31, loss = 0.00422074\n",
      "Iteration 32, loss = 0.00301069\n",
      "Iteration 33, loss = 0.00347058\n",
      "Iteration 34, loss = 0.00211628\n",
      "Iteration 35, loss = 0.00150913\n",
      "Iteration 36, loss = 0.00131208\n",
      "Iteration 37, loss = 0.00117773\n",
      "Iteration 38, loss = 0.00116949\n",
      "Iteration 39, loss = 0.00086759\n",
      "Iteration 40, loss = 0.00074322\n",
      "Iteration 41, loss = 0.00067194\n",
      "Iteration 42, loss = 0.00060243\n",
      "Iteration 43, loss = 0.00055501\n",
      "Iteration 44, loss = 0.00050733\n",
      "Iteration 45, loss = 0.00046995\n",
      "Iteration 46, loss = 0.00043936\n",
      "Iteration 47, loss = 0.00040097\n",
      "Iteration 48, loss = 0.00040994\n",
      "Iteration 49, loss = 0.00036530\n",
      "Iteration 50, loss = 0.00032089\n",
      "Iteration 51, loss = 0.00028854\n",
      "Iteration 52, loss = 0.00028090\n",
      "Iteration 53, loss = 0.00024671\n",
      "Iteration 54, loss = 0.00022741\n",
      "Iteration 55, loss = 0.00021649\n",
      "Iteration 56, loss = 0.00019564\n",
      "Iteration 57, loss = 0.00018274\n",
      "Iteration 58, loss = 0.00018276\n",
      "Iteration 59, loss = 0.00015788\n",
      "Iteration 60, loss = 0.00014920\n",
      "Iteration 61, loss = 0.00013686\n",
      "Iteration 62, loss = 0.00013366\n",
      "Iteration 63, loss = 0.00012199\n",
      "Iteration 64, loss = 0.00010724\n",
      "Iteration 65, loss = 0.00009845\n",
      "Iteration 66, loss = 0.00009112\n",
      "Iteration 67, loss = 0.00008679\n",
      "Iteration 68, loss = 0.00007758\n",
      "Iteration 69, loss = 0.00007201\n",
      "Iteration 70, loss = 0.00006729\n",
      "Iteration 71, loss = 0.00006430\n",
      "Iteration 72, loss = 0.00006181\n",
      "Iteration 73, loss = 0.00005416\n",
      "Iteration 74, loss = 0.00005119\n",
      "Iteration 75, loss = 0.00004514\n",
      "Iteration 76, loss = 0.00005105\n",
      "Iteration 77, loss = 0.00004276\n",
      "Iteration 78, loss = 0.00003753\n",
      "Iteration 79, loss = 0.00003942\n",
      "Iteration 80, loss = 0.00003328\n",
      "Iteration 81, loss = 0.00003040\n",
      "Iteration 82, loss = 0.00002759\n",
      "Iteration 83, loss = 0.00002509\n",
      "Iteration 84, loss = 0.00002336\n",
      "Iteration 85, loss = 0.00002204\n",
      "Iteration 86, loss = 0.00002052\n",
      "Iteration 87, loss = 0.00001990\n",
      "Iteration 88, loss = 0.00001802\n",
      "Iteration 89, loss = 0.00001653\n",
      "Iteration 90, loss = 0.00001553\n",
      "Iteration 91, loss = 0.00001556\n",
      "Iteration 92, loss = 0.00001350\n",
      "Iteration 93, loss = 0.00001275\n",
      "Iteration 94, loss = 0.00001205\n",
      "Iteration 95, loss = 0.00001087\n",
      "Iteration 96, loss = 0.00000992\n",
      "Iteration 97, loss = 0.00000930\n",
      "Iteration 98, loss = 0.00000880\n",
      "Iteration 99, loss = 0.00000811\n",
      "Iteration 100, loss = 0.00000799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zb0857\\AppData\\Local\\Continuum\\anaconda3\\envs\\ML\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0, batch_size=500, beta_1=0.9,\n",
       "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "              hidden_layer_sizes=(100, 100), learning_rate='constant',\n",
       "              learning_rate_init=0.001, max_iter=100, momentum=0.9,\n",
       "              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "              random_state=1234, shuffle=True, solver='adam', tol=-10.0,\n",
       "              validation_fraction=0.1, verbose=True, warm_start=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train the network\n",
    "\n",
    "MLP_clf.fit(x_train, y_train0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.797488053580999e-06"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Predicting\n",
    "\n",
    "y_train_hat_clf_sk = MLP_clf.predict_proba(x_train)\n",
    "\n",
    "log_loss(y_train0, y_train_hat_clf_sk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(y_train0[0])\n",
    "print(y_train0[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.70809940e-29 9.81606200e-27 1.15198413e-26 1.23578550e-06\n",
      " 1.73868478e-48 9.99998764e-01 3.36232818e-34 1.61854154e-27\n",
      " 5.19096082e-25 3.67395431e-26]\n",
      "[1.00000000e+00 1.31448414e-34 6.10330686e-17 2.18557786e-26\n",
      " 6.92783645e-43 2.23946052e-27 2.50928070e-23 7.97880469e-30\n",
      " 1.71811914e-30 4.21395358e-19]\n"
     ]
    }
   ],
   "source": [
    "print(y_train_hat_clf_sk[0])\n",
    "print(y_train_hat_clf_sk[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Layers:  3\n",
      "Weights layer 1:  78500\n",
      "Weights layer 2:  10100\n",
      "Weights layer 3:  1010\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of Layers: \", len(MLP_clf.coefs_))\n",
    "print(\"Weights layer 1: \", MLP_clf.coefs_[0].size+MLP_clf.intercepts_[0].size)\n",
    "print(\"Weights layer 2: \", MLP_clf.coefs_[1].size+MLP_clf.intercepts_[1].size)\n",
    "print(\"Weights layer 3: \", MLP_clf.coefs_[2].size+MLP_clf.intercepts_[2].size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "softmax\n",
      "multiclass\n"
     ]
    }
   ],
   "source": [
    "print(MLP_clf.out_activation_)\n",
    "print(MLP_clf._label_binarizer.y_type_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x246850abdd8>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1,1)\n",
    "ax.plot(MLP_clf.loss_curve_, label=\"SciKitLearn\")\n",
    "ax.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

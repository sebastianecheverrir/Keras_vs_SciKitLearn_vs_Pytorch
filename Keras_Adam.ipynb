{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import seed\n",
    "import numpy as np\n",
    "seed(1)\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(2)\n",
    "\n",
    "import tensorflow as tf\n",
    "# from tensorflow.python.keras.optimizers import Fire\n",
    "from tensorflow.python.keras.optimizers import Adam\n",
    "from tensorflow.python.keras import backend as K\n",
    "from tensorflow.python.keras import optimizers\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the input data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preparing the input data\n",
    "\n",
    "#loading the MNIST dataset\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "#Separating into train and test (60000 train, 10000 test)\n",
    "(x_train, y_train0),(x_test, y_test0) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "#flattening the images (from 28x28 to 784)\n",
    "x_train = x_train.reshape(60000, 784)\n",
    "x_test = x_test.reshape(10000, 784)\n",
    "\n",
    "#converting the otputs (labels) into one hot vectors\n",
    "lb = preprocessing.LabelBinarizer()\n",
    "lb.fit(np.array([0,1,2,3,4,5,6,7,8,9]))\n",
    "y_train = lb.transform(y_train0)\n",
    "y_test = lb.transform(y_test0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the input parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining the input parameters\n",
    "BatchSize         = 500\n",
    "NeuronsLayer1     = 100\n",
    "NeuronsLayer2     = 100\n",
    "Epochs            = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model in tensorflow/Keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow.python.keras.engine.sequential.Sequential object at 0x000001C9361622E8>\n"
     ]
    }
   ],
   "source": [
    "# Defining the net\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Dense(NeuronsLayer1,\n",
    "                        activation=tf.nn.relu),\n",
    "  tf.keras.layers.Dense(NeuronsLayer2, \n",
    "                        activation=tf.nn.relu),\n",
    "  #  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(10, \n",
    "                        activation=tf.nn.softmax)\n",
    "                                   ])\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct our model, # Construct our loss function and an Optimizer. \n",
    "\n",
    "loss = tf.keras.backend.categorical_crossentropy\n",
    "optimizer = optimizers.Adam()\n",
    "\n",
    "model.compile(optimizer= optimizer,\n",
    "              loss=loss ) #'categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "60000/60000 [==============================] - 2s 36us/step - loss: 0.5677\n",
      "Epoch 2/100\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.2097\n",
      "Epoch 3/100\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.1559\n",
      "Epoch 4/100\n",
      "60000/60000 [==============================] - 2s 36us/step - loss: 0.1241\n",
      "Epoch 5/100\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.1023\n",
      "Epoch 6/100\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.0855\n",
      "Epoch 7/100\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.0742\n",
      "Epoch 8/100\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0654\n",
      "Epoch 9/100\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0577\n",
      "Epoch 10/100\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.0505\n",
      "Epoch 11/100\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.0455\n",
      "Epoch 12/100\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.0396\n",
      "Epoch 13/100\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.0352\n",
      "Epoch 14/100\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.0311\n",
      "Epoch 15/100\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.0287\n",
      "Epoch 16/100\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.0262\n",
      "Epoch 17/100\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.0232\n",
      "Epoch 18/100\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.0208\n",
      "Epoch 19/100\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0180\n",
      "Epoch 20/100\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.0149\n",
      "Epoch 21/100\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0133\n",
      "Epoch 22/100\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.0110\n",
      "Epoch 23/100\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.0106\n",
      "Epoch 24/100\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.0096\n",
      "Epoch 25/100\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.0087\n",
      "Epoch 26/100\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.0067\n",
      "Epoch 27/100\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.0056\n",
      "Epoch 28/100\n",
      "60000/60000 [==============================] - 2s 37us/step - loss: 0.0051\n",
      "Epoch 29/100\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.0045\n",
      "Epoch 30/100\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.0042\n",
      "Epoch 31/100\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.0037\n",
      "Epoch 32/100\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.0068\n",
      "Epoch 33/100\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.0067\n",
      "Epoch 34/100\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.0044\n",
      "Epoch 35/100\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.0034\n",
      "Epoch 36/100\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0020\n",
      "Epoch 37/100\n",
      "60000/60000 [==============================] - 2s 36us/step - loss: 0.0013\n",
      "Epoch 38/100\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.0012\n",
      "Epoch 39/100\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 9.6380e-04\n",
      "Epoch 40/100\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 8.4092e-04\n",
      "Epoch 41/100\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 7.4833e-04\n",
      "Epoch 42/100\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 6.8888e-04\n",
      "Epoch 43/100\n",
      "60000/60000 [==============================] - 2s 35us/step - loss: 6.4980e-04\n",
      "Epoch 44/100\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 5.9640e-04\n",
      "Epoch 45/100\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 9.8922e-04\n",
      "Epoch 46/100\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.0269\n",
      "Epoch 47/100\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.0176\n",
      "Epoch 48/100\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.0066\n",
      "Epoch 49/100\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.0022\n",
      "Epoch 50/100\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 8.6846e-04\n",
      "Epoch 51/100\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 5.2975e-04\n",
      "Epoch 52/100\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 4.3601e-04\n",
      "Epoch 53/100\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 3.8668e-04\n",
      "Epoch 54/100\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 3.5091e-04\n",
      "Epoch 55/100\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 3.2558e-04\n",
      "Epoch 56/100\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 3.0369e-04\n",
      "Epoch 57/100\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 2.8463e-04\n",
      "Epoch 58/100\n",
      "60000/60000 [==============================] - 2s 35us/step - loss: 2.6288e-04\n",
      "Epoch 59/100\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 2.4699e-04\n",
      "Epoch 60/100\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 2.3226e-04\n",
      "Epoch 61/100\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 2.1771e-04\n",
      "Epoch 62/100\n",
      "60000/60000 [==============================] - 2s 35us/step - loss: 2.0968e-04\n",
      "Epoch 63/100\n",
      "60000/60000 [==============================] - 2s 37us/step - loss: 1.9721e-04\n",
      "Epoch 64/100\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 1.8802e-04\n",
      "Epoch 65/100\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 1.7501e-04\n",
      "Epoch 66/100\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 1.6455e-04\n",
      "Epoch 67/100\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 1.5652e-04\n",
      "Epoch 68/100\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 1.4935e-04\n",
      "Epoch 69/100\n",
      "60000/60000 [==============================] - 2s 38us/step - loss: 1.4147e-04\n",
      "Epoch 70/100\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 1.3404e-04\n",
      "Epoch 71/100\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 1.2552e-04\n",
      "Epoch 72/100\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 1.1952e-04\n",
      "Epoch 73/100\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 1.1301e-04\n",
      "Epoch 74/100\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 1.0741e-04\n",
      "Epoch 75/100\n",
      "60000/60000 [==============================] - 2s 35us/step - loss: 1.0096e-04\n",
      "Epoch 76/100\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 9.4013e-05\n",
      "Epoch 77/100\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 9.1797e-05\n",
      "Epoch 78/100\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 8.6505e-05\n",
      "Epoch 79/100\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 8.0380e-05\n",
      "Epoch 80/100\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 7.8477e-05\n",
      "Epoch 81/100\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 7.2596e-05\n",
      "Epoch 82/100\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 6.7935e-05\n",
      "Epoch 83/100\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 6.2301e-05\n",
      "Epoch 84/100\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 5.9792e-05\n",
      "Epoch 85/100\n",
      "60000/60000 [==============================] - 2s 35us/step - loss: 5.6886e-05\n",
      "Epoch 86/100\n",
      "60000/60000 [==============================] - 2s 35us/step - loss: 5.3353e-05\n",
      "Epoch 87/100\n",
      "60000/60000 [==============================] - 2s 35us/step - loss: 5.0211e-05\n",
      "Epoch 88/100\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 4.7557e-05\n",
      "Epoch 89/100\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 4.8601e-05\n",
      "Epoch 90/100\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 4.3518e-05\n",
      "Epoch 91/100\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 3.9225e-05\n",
      "Epoch 92/100\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 3.6222e-05\n",
      "Epoch 93/100\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 3.4281e-05\n",
      "Epoch 94/100\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 3.2039e-05\n",
      "Epoch 95/100\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 2.9783e-05\n",
      "Epoch 96/100\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 2.8451e-05\n",
      "Epoch 97/100\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 2.6705e-05\n",
      "Epoch 98/100\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 2.5968e-05\n",
      "Epoch 99/100\n",
      "60000/60000 [==============================] - 2s 35us/step - loss: 2.3498e-05\n",
      "Epoch 100/100\n",
      "60000/60000 [==============================] - 2s 37us/step - loss: 2.1900e-05\n"
     ]
    }
   ],
   "source": [
    "#train the network\n",
    "\n",
    "HistoryKeras = model.fit(  x_train, y_train, \n",
    "            epochs=Epochs,\n",
    "            batch_size=BatchSize)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.905785308988257e-05"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Predicting\n",
    "\n",
    "#model.evaluate(x_test, y_test)\n",
    "y_train_hat_keras = model.predict_proba(x_train)\n",
    "\n",
    "log_loss(y_train, y_train_hat_keras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 1 0 0 0 0]\n",
      "[1 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(y_train[0])\n",
    "print(y_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.59248151e-30 4.10511780e-31 9.87905524e-29 3.78195153e-07\n",
      " 0.00000000e+00 9.99999642e-01 7.33457418e-37 1.08409536e-29\n",
      " 9.69164618e-27 3.67397989e-25]\n",
      "[1.0000000e+00 4.4683167e-25 1.6138398e-12 9.3892560e-24 4.4029505e-34\n",
      " 1.3528748e-28 1.5309506e-21 4.4388996e-29 7.0907248e-27 1.9980291e-23]\n"
     ]
    }
   ],
   "source": [
    "print(y_train_hat_keras[0])\n",
    "print(y_train_hat_keras[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                multiple                  78500     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              multiple                  10100     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              multiple                  1010      \n",
      "=================================================================\n",
      "Total params: 89,610\n",
      "Trainable params: 89,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Show aprameters of the network\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1c936ce3208>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1,1)\n",
    "ax.plot(model.history.history['loss'], label=\"Keras\")\n",
    "ax.legend()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

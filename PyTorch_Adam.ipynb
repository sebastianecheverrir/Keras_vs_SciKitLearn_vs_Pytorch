{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import seed\n",
    "import numpy as np\n",
    "seed(1)\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(2)\n",
    "\n",
    "import tensorflow as tf\n",
    "# from tensorflow.python.keras.optimizers import Fire\n",
    "from tensorflow.python.keras.optimizers import Adam\n",
    "from tensorflow.python.keras import backend as K\n",
    "from tensorflow.python.keras import optimizers\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data\n",
    "from torch.autograd import Variable\n",
    "from torchsummary import summary\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preparing the input data\n",
    "\n",
    "#loading the MNIST dataset\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "#Separating into train and test (60000 train, 10000 test)\n",
    "(x_train, y_train0),(x_test, y_test0) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "#flattening the images (from 28x28 to 784)\n",
    "x_train = x_train.reshape(60000, 784)\n",
    "x_test = x_test.reshape(10000, 784)\n",
    "\n",
    "\n",
    "#converting the otputs (labels) into one hot vectors\n",
    "lb = preprocessing.LabelBinarizer()\n",
    "lb.fit(np.array([0,1,2,3,4,5,6,7,8,9]))\n",
    "y_train = lb.transform(y_train0)\n",
    "y_test = lb.transform(y_test0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the input parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining the input parameters\n",
    "BatchSize         = 500\n",
    "NeuronsLayer1     = 100\n",
    "NeuronsLayer2     = 100\n",
    "Epochs            = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Tensors to hold inputs and outputs\n",
    "\n",
    "torch_X_train = torch.from_numpy(x_train)\n",
    "torch_y_train = torch.from_numpy(y_train)\n",
    "\n",
    "#the trainloader helps us deal with the batches\n",
    "train = torch.utils.data.TensorDataset(torch_X_train.float(),torch_y_train.float())\n",
    "train_loader = torch.utils.data.DataLoader(train, batch_size = BatchSize, shuffle = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the net\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        self.linear1 = nn.Linear(784,NeuronsLayer1)\n",
    "        self.linear2 = nn.Linear(NeuronsLayer1,NeuronsLayer2)\n",
    "        self.linear3 = nn.Linear(NeuronsLayer2,10)\n",
    "    \n",
    "    def forward(self,X):\n",
    "        X = F.relu(self.linear1(X))\n",
    "        X = F.relu(self.linear2(X))\n",
    "        X = F.softmax(self.linear3(X), dim=1)\n",
    "        return X\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct our model by instantiating the class defined above.\n",
    "model = MLP()\n",
    "\n",
    "\n",
    "# Construct our loss function and an Optimizer. \n",
    "\n",
    "#it seems that cateorical cross-entropy is not available in pytorch. We have to make or own\n",
    "#    implementation of the loss function\n",
    "#https://datascience.stackexchange.com/questions/55962/pytorch-doing-a-cross-entropy-loss-when-the-predictions-already-have-probabiliti\n",
    "def categorical_cross_entropy(y_pred, y_true):\n",
    "    y_pred = torch.clamp(y_pred, 1e-9, 1 - 1e-9)\n",
    "    return -(y_true * torch.log(y_pred)).sum(dim=1).mean()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.parameters of MLP(\n",
       "  (linear1): Linear(in_features=784, out_features=100, bias=True)\n",
       "  (linear2): Linear(in_features=100, out_features=100, bias=True)\n",
       "  (linear3): Linear(in_features=100, out_features=10, bias=True)\n",
       ")>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Show aprameters of the network\n",
    "model.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.2693708837032318 0.743281010662516\n",
      "2 0.21981947124004364 0.2772692972794175\n",
      "3 0.19280613958835602 0.2158559529731671\n",
      "4 0.17550921440124512 0.1791273138175408\n",
      "5 0.16534960269927979 0.1535166815544168\n",
      "6 0.15742802619934082 0.13422945123165847\n",
      "7 0.14997263252735138 0.11879941740383705\n",
      "8 0.14199405908584595 0.10619592033326626\n",
      "9 0.13392777740955353 0.09573884656031927\n",
      "10 0.1260603666305542 0.08651566961780191\n",
      "11 0.11908599734306335 0.07860302540163198\n",
      "12 0.1111280545592308 0.0715199768388023\n",
      "13 0.10289566218852997 0.06518746381625533\n",
      "14 0.0940386950969696 0.05967147024348378\n",
      "15 0.08516008406877518 0.0546204901766032\n",
      "16 0.07843393087387085 0.04993509304088851\n",
      "17 0.07150780409574509 0.04575526515642802\n",
      "18 0.06507837772369385 0.04206505216037234\n",
      "19 0.0596977099776268 0.038715300639159976\n",
      "20 0.05255799740552902 0.03564774300903082\n",
      "21 0.046331822872161865 0.032808993097084266\n",
      "22 0.03918847441673279 0.030123332538641988\n",
      "23 0.0335158035159111 0.02770062449077765\n",
      "24 0.027444036677479744 0.025455722790987543\n",
      "25 0.021598124876618385 0.02337244200753048\n",
      "26 0.018717365339398384 0.02134388591318081\n",
      "27 0.01790914498269558 0.01971600472073381\n",
      "28 0.016962062567472458 0.01891101636768629\n",
      "29 0.016336752101778984 0.018789293011650443\n",
      "30 0.014298147521913052 0.01917228503152728\n",
      "31 0.012909340672194958 0.0178227165248245\n",
      "32 0.01605314202606678 0.01635579343031471\n",
      "33 0.008235600776970387 0.014852761126045758\n",
      "34 0.00832899659872055 0.014515087020117789\n",
      "35 0.010262101888656616 0.014020589459687472\n",
      "36 0.008272740989923477 0.014209113469890629\n",
      "37 0.0088179437443614 0.013770677162877594\n",
      "38 0.013327054679393768 0.01306511420601358\n",
      "39 0.01352508645504713 0.009202250265904393\n",
      "40 0.007511603645980358 0.007674341180245392\n",
      "41 0.004939643666148186 0.005729513689099501\n",
      "42 0.004908241797238588 0.004917789209381833\n",
      "43 0.002991407411172986 0.004035165649838746\n",
      "44 0.0032580022234469652 0.0031109141525424394\n",
      "45 0.0021145243663340807 0.002569649689879346\n",
      "46 0.0020475396886467934 0.0023002261771277216\n",
      "47 0.0018285887781530619 0.0021201600808126385\n",
      "48 0.001542015466839075 0.0018873542686681807\n",
      "49 0.00112057919614017 0.001774566845294127\n",
      "50 0.0008620095904916525 0.0015759376947850493\n",
      "51 0.0008708484820090234 0.0014023459217545073\n",
      "52 0.0007335058180615306 0.0012830471553267368\n",
      "53 0.0016151323216035962 0.0013071076270231667\n",
      "54 0.0015369426691904664 0.001334141506110124\n",
      "55 0.0006981374463066459 0.0013191724688416191\n",
      "56 0.0004319963336456567 0.001049277570200502\n",
      "57 0.0004130586457904428 0.0008702040078181502\n",
      "58 0.0005812591407448053 0.0007226817908910258\n",
      "59 0.00042113912058994174 0.0008192425844147995\n",
      "60 0.0017760114278644323 0.0015629084210862251\n",
      "61 0.026340430602431297 0.017860572779318316\n",
      "62 0.005040442105382681 0.0189234209159622\n",
      "63 0.0066065494902431965 0.010334340400974421\n",
      "64 0.0006805842276662588 0.003400872549051807\n",
      "65 0.00040971385897137225 0.001248462021552162\n",
      "66 0.00035502869286574423 0.0009388698505669405\n",
      "67 0.0002866984286811203 0.0006245534582679587\n",
      "68 0.00025019023451022804 0.0004252970627021568\n",
      "69 0.00022185184934642166 0.0003526791898366355\n",
      "70 0.00020060832321178168 0.00029874756285911037\n",
      "71 0.00018495673430152237 0.00026487012028155734\n",
      "72 0.00017074981587938964 0.00023960086852336341\n",
      "73 0.00015963926853146404 0.00021886578427559772\n",
      "74 0.00014901303802616894 0.000202619667682787\n",
      "75 0.00014097403618507087 0.00018838402268859985\n",
      "76 0.00013366495841182768 0.00017600425004881496\n",
      "77 0.0001270203647436574 0.0001648391064918542\n",
      "78 0.00012094566773157567 0.00015486856248874876\n",
      "79 0.00011600975994952023 0.00014588596335064115\n",
      "80 0.00011057995288865641 0.00013776923760815406\n",
      "81 0.00010563195974100381 0.00012999328085546344\n",
      "82 0.00010070580174215138 0.00012285189723115764\n",
      "83 9.515550482319668e-05 0.00011600873249335563\n",
      "84 9.049305663211271e-05 0.00010984679599156759\n",
      "85 8.606523624621332e-05 0.00010391655849465073\n",
      "86 8.198139403248206e-05 9.830296974845017e-05\n",
      "87 7.74158033891581e-05 9.311357633426573e-05\n",
      "88 7.334027759497985e-05 8.81762914104911e-05\n",
      "89 6.965229113120586e-05 8.349663886898876e-05\n",
      "90 6.574951112270355e-05 7.905926575707175e-05\n",
      "91 6.214982568053529e-05 7.482643742757015e-05\n",
      "92 5.885697464691475e-05 7.08753749980436e-05\n",
      "93 5.572440932155587e-05 6.70582913699036e-05\n",
      "94 5.2672650781460106e-05 6.352770269586472e-05\n",
      "95 5.012789188185707e-05 6.0149979041549766e-05\n",
      "96 4.722182347904891e-05 5.68775143771442e-05\n",
      "97 4.456619353732094e-05 5.378295228031978e-05\n",
      "98 4.248509503668174e-05 5.087420452885756e-05\n",
      "99 3.9662882045377046e-05 4.805148475952592e-05\n",
      "100 3.7892019463470206e-05 4.538110889219145e-05\n"
     ]
    }
   ],
   "source": [
    "#train the network\n",
    "\n",
    "loss_history = []\n",
    "for epoch in range(Epochs):\n",
    "    loss_avg = 0.0\n",
    "    N_elements = 0\n",
    "    for batch_idx, (X_batch, y_batch) in enumerate(train_loader):\n",
    "        # Forward pass: Compute predicted y by passing x to the model\n",
    "        y_pred = model(X_batch)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = categorical_cross_entropy(y_pred, y_batch)\n",
    "\n",
    "        # Zero gradients, perform a backward pass, and update the weights.\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_avg += loss.item()*X_batch.size()[0]\n",
    "        N_elements += X_batch.size()[0]\n",
    "\n",
    "    # print loss after each epoch    \n",
    "    print(epoch+1, loss.item(), loss_avg/N_elements)\n",
    "    loss_history.append(loss_avg/N_elements)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.9600766990670783e-05\n"
     ]
    }
   ],
   "source": [
    "#Predicting\n",
    "y_train_hat_Pytorch = model(torch_X_train.float()).detach().numpy()\n",
    "\n",
    "print(log_loss(y_train, y_train_hat_Pytorch))\n",
    "# print(categorical_cross_entropy(torch.from_numpy(y_train).float(), torch.from_numpy(y_train_hat_Pytorch)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 1 0 0 0 0]\n",
      "[1 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(y_train[0])\n",
    "print(y_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.1013711e-31 4.1455269e-23 1.5996665e-20 6.6180510e-05 0.0000000e+00\n",
      " 9.9993384e-01 1.8145858e-32 1.0823392e-27 2.8055580e-32 3.1600519e-21]\n",
      "[1.0000000e+00 5.4496440e-35 9.2110968e-16 6.1589742e-28 2.9754415e-39\n",
      " 3.3539346e-27 2.4967089e-24 8.7443980e-26 2.3347575e-30 1.7749837e-23]\n"
     ]
    }
   ],
   "source": [
    "print(y_train_hat_Pytorch[0])\n",
    "print(y_train_hat_Pytorch[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1               [-1, 1, 100]          78,500\n",
      "            Linear-2               [-1, 1, 100]          10,100\n",
      "            Linear-3                [-1, 1, 10]           1,010\n",
      "================================================================\n",
      "Total params: 89,610\n",
      "Trainable params: 89,610\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.00\n",
      "Params size (MB): 0.34\n",
      "Estimated Total Size (MB): 0.35\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#Show aprameters of the network\n",
    "\n",
    "summary(model, (1, 784))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x16bd6638c18>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzt3Xt4VPW97/H3d24BwjUh3MEExQs3QSPFG7tWWsHugrZawdOb2uPTp/XUbnt2jz6eunfts89p697tsT2cWuqt7a6laq3SlkrrpbViUaKAchGNiBBACPdLgGQy3/PHTHBIZpIhTBjW5PN6njxkrfllzXex4JPf/NZvrWXujoiIFJdQoQsQEZH8U7iLiBQhhbuISBFSuIuIFCGFu4hIEVK4i4gUIYW7iEgRUriLiBQhhbuISBGKFOqNBw4c6JWVlYV6exGRQHr11Vd3uHtFR+0KFu6VlZXU1NQU6u1FRALJzN7LpZ2GZUREipDCXUSkCCncRUSKUMHG3EWk+2lqaqKuro7Dhw8XupRTXo8ePRgxYgTRaLRTP69wF5GTpq6ujj59+lBZWYmZFbqcU5a7s3PnTurq6qiqqurUNjQsIyInzeHDhykvL1ewd8DMKC8vP6FPOAp3ETmpFOy5OdG/p8CF+7INu/iPP60j3pwodCkiIqeswIX78o27+dFztRyJK9xF5PiFw2EmTZrE+PHjufbaa2loaMjY7o033mDSpElMmjSJsrIyqqqqmDRpEtOnTz/hGj7zmc/w5JNPnvB22hO4cI+GkyU3KtxFpBN69uzJihUrWLVqFbFYjPvuuy9juwkTJrBixQpWrFjBrFmzuOeee1ixYgXPPPNMTu8Tj8fzWfZxC2y4N2lYRkRO0KWXXkptbS3f/OY3uffee4+uv/POO/nhD3+Y9ecSiQS33XYb48ePZ8KECTz++OMAPPPMM0yfPp05c+YwefJkAB566CEmTpzIueeeyw033HB0G88//zwXXXQRo0eP5re//W3e9y1wUyFjkVTPXeEuEmjf+t1q1mzZl9dtjh3Wl3/5xLic2sbjcf74xz8yY8YMZs6cySc/+UluvfVWEokECxYs4JVXXsn6s4899hhr1qxh5cqV1NfXc8EFFzBt2jQAli5dypo1axg1ahQrV67ku9/9Li+99BJlZWXs2rXr6Da2b9/OkiVLeOONN/j0pz/N1VdffWI730rwwl3DMiJyAg4dOsSkSZOAZM/9pptuIhaLUV5ezvLly9m2bRuTJ0+mvLw86zZefPFFrr/+esLhMEOGDOGSSy6hpqaGWCzGhRdeyKhRowB47rnnuO666ygrKwM4+ifAVVddhZkxceJENm/enPf9DFy4fzAs4wWuRERORK497HxrGXNv7Ytf/CIPP/ww77//PjfeeGO723DPnj+lpaXHtMs2pbGkpCSn7XVW4MbcW4ZlNOYuIvl09dVX8/TTT7Ns2TKuuOKKdttOmzaNBQsW0NzczLZt21iyZAnV1dVt2k2fPp0FCxYcHY5JH5bpagHsuSd/C2oqpIjkUywW47LLLqN///6Ew+F2215zzTUsXbqUc889FzPj+9//PoMGDWrTbuLEiXzjG99g2rRpRCIRzj//fB544IGu2oVjWC4fB8xsBnAvEAbud/fvtHr9B8BlqcVewCB379/eNqurq70zD+t4qXYH19//MgtunsrU0dnHxETk1LN27VrOOeecQpeRUSKR4LzzzuOxxx5jzJgxhS4HyPz3ZWavunvbjwmtdDgsY2ZhYB4wExgLzDWzselt3P2f3H2Su08CfgQ8cRz1HxcNy4hIvq1Zs4YzzjiDyy+//JQJ9hOVy7DMFKDW3dcDmNkCYDawJkv7ucC/5Ke8tnQRk4jk29ixY1m/fn2hy8irXE6oDgc2pS3Xpda1YWanAVXAcydeWma6iEkk2LpiZkgxOtG/p1zCPdM8nmzvOgd43N2bM27I7GYzqzGzmvr6+lxrPMYHFzHpH4hI0PTo0YOdO3cq4DvQcj/3Hj16dHobuQzL1AEj05ZHAFuytJ0DfCXbhtx9PjAfkidUc6zxGLqISSS4RowYQV1dHZ3t3HUnLU9i6qxcwn0ZMMbMqoDNJAP8+taNzOwsYADw905XkwOdUBUJrmg02uknC8nx6XBYxt3jwC3AYmAt8Ki7rzazu81sVlrTucAC7+LPWy3z3NVzFxHJLqeLmNx9EbCo1bq7Wi3/a/7Kyi6qnruISIeCd/uBsO4KKSLSkcCFu+a5i4h0LHDhHg4Z4ZBpWEZEpB2BC3dIDs3olr8iItkFMtyjYdOwjIhIOwIZ7rFISCdURUTaEcxwD4doUs9dRCSrQIZ7VD13EZF2BTPcwyHNlhERaUcgwz0WDtEY12wZEZFsAhnuGpYREWlfIMM9FjadUBURaUcwwz2iMXcRkfYEMtyjYQ3LiIi0J5DhnjyhqnAXEckmkOGuE6oiIu0LZLjHNM9dRKRdwQ13zXMXEckqp3A3sxlmts7Mas3s9ixtPm1ma8xstZk9kt8yjxWNmIZlRETa0eEzVM0sDMwDPgrUAcvMbKG7r0lrMwa4A7jY3Xeb2aCuKhhStx/QCVURkaxy6blPAWrdfb27NwILgNmt2vxXYJ677wZw9+35LfNYuuWviEj7cgn34cCmtOW61Lp0ZwJnmtkSM1tqZjMybcjMbjazGjOrqa+v71zFpKZCNidw17i7iEgmuYS7ZVjXOlUjwBjgw8Bc4H4z69/mh9znu3u1u1dXVFQcb61HRcMh3KE5oXAXEckkl3CvA0amLY8AtmRo85S7N7n7u8A6kmHfJWKRZNl6jqqISGa5hPsyYIyZVZlZDJgDLGzV5kngMgAzG0hymGZ9PgtNFw0ny9ZVqiIimXUY7u4eB24BFgNrgUfdfbWZ3W1ms1LNFgM7zWwN8Dzwz+6+s6uKjoWTI0U6qSoiklmHUyEB3H0RsKjVurvSvnfgttRXl/tgWEbhLiKSSSCvUNWwjIhI+wId7uq5i4hkFshwbxmWOaKeu4hIRsEMd/XcRUTaFchw/2BYRvPcRUQyCWS4twzL6ISqiEhmgQz3aGqeu4ZlREQyC2S4H+25K9xFRDIKZrhrnruISLsCGe6a5y4i0r5AhrtuPyAi0r5AhrtuPyAi0r5AhvvRMXfNcxcRySiY4a5hGRGRdgUy3FvmuWtYRkQks0CGezhkmKnnLiKSTSDD3cyIhUO6iElEJIucwt3MZpjZOjOrNbPbM7z+BTOrN7MVqa8v5r/UY8XCIQ3LiIhk0eFj9swsDMwDPgrUAcvMbKG7r2nV9NfufksX1JhRNBLSsIyISBa59NynALXuvt7dG4EFwOyuLatj6rmLiGSXS7gPBzalLdel1rX2KTN73cweN7OReamuHdGI6X7uIiJZ5BLulmFd61T9HVDp7hOBZ4CfZdyQ2c1mVmNmNfX19cdXaStRnVAVEckql3CvA9J74iOALekN3H2nux9JLf4UOD/Thtx9vrtXu3t1RUVFZ+o9SsMyIiLZ5RLuy4AxZlZlZjFgDrAwvYGZDU1bnAWszV+JmcV0QlVEJKsOZ8u4e9zMbgEWA2HgQXdfbWZ3AzXuvhD4qpnNAuLALuALXVgzkOy5K9xFRDLrMNwB3H0RsKjVurvSvr8DuCO/pbUvqmEZEZGsAnmFKiTnueuukCIimQU23GPhEE3quYuIZBTccI+YpkKKiGQR2HCP6oSqiEhWgQ13DcuIiGQX2HBPnlBVuIuIZBLYcNcVqiIi2QU33NVzFxHJKrDhHg3rrpAiItkEONxDNCec5oQCXkSktcCGeyySLF3TIUVE2gpuuIeTpWvcXUSkrcCGezQV7prrLiLSVmDDvWVYRj13EZG2AhvuH/TcdUJVRKS1AId78tGu6rmLiLQV2HAvaRmW0Zi7iEgbgQ33o8My6rmLiLSRU7ib2QwzW2dmtWZ2ezvtrjEzN7Pq/JWYmea5i4hk12G4m1kYmAfMBMYCc81sbIZ2fYCvAi/nu8hMWnruGpYREWkrl577FKDW3de7eyOwAJidod23ge8Bh/NYX1ZRXcQkIpJVLuE+HNiUtlyXWneUmU0GRrr77/NYW7tKjg7LaCqkiEhruYS7ZVh3NFHNLAT8APh6hxsyu9nMasyspr6+PvcqM9CwjIhIdrmEex0wMm15BLAlbbkPMB74i5ltAKYCCzOdVHX3+e5e7e7VFRUVna+aD+a564SqiEhbuYT7MmCMmVWZWQyYAyxsedHd97r7QHevdPdKYCkwy91ruqTilJjmuYuIZNVhuLt7HLgFWAysBR5199VmdreZzerqArPRXSFFRLKL5NLI3RcBi1qtuytL2w+feFkd00VMIiLZBfYKVQ3LiIhkF9hwV89dRCS7AId7y10hNc9dRKS1wIa7mRELhzQsIyKSQWDDHZK9dw3LiIi0Fexwj4QU7iIiGQQ63DUsIyKSWaDDPRoO6SImEZEMAh3uJZGQ7gopIpJBoMM9Gg7RGG8udBkiIqecYId7xNRzFxHJINDhrhOqIiKZBTrcdUJVRCSzQId7TPPcRUQyCna4a1hGRCSjQId7NKyeu4hIJsEOd81zFxHJKKdwN7MZZrbOzGrN7PYMr3/JzN4wsxVm9qKZjc1/qW1pWEZEJLMOw93MwsA8YCYwFpibIbwfcfcJ7j4J+B7w/bxXmkEsYpotIyKSQS499ylArbuvd/dGYAEwO72Bu+9LWywFTspYicbcRUQyy+UB2cOBTWnLdcCHWjcys68AtwEx4CN5qa4DGpYREcksl567ZVjXpmfu7vPc/XTgfwD/M+OGzG42sxozq6mvrz++SjPQ/dxFRDLLJdzrgJFpyyOALe20XwBclekFd5/v7tXuXl1RUZF7lVkkh2Ucd82YERFJl0u4LwPGmFmVmcWAOcDC9AZmNiZt8ePA2/krMbuSSLJ8nVQVETlWh2Pu7h43s1uAxUAYeNDdV5vZ3UCNuy8EbjGz6UATsBv4fFcW3SIaTo4YNTU7JbmcPRAR6SZyikR3XwQsarXurrTvb81zXTmJhZM996Z4AkoKUYGIyKkp8FeogoZlRERaC3S49+sZBaB+/5ECVyIicmoJdLifM7QvAGu27uugpYhI9xLocK8sL6VnNMyaLQp3EZF0gQ73cMg4e2gf9dxFRFoJdLgDjBvWl7Vb9ulCJhGRNIEP97FD+7H/SJxNuw4VuhQRkVNG8MN9WMtJ1b0FrkRE5NQR+HA/a3AfQoZOqoqIpAl8uPeMhRld0VsnVUVE0gQ+3CF5UlU9dxGRDxRFuI8d2pctew+z+2BjoUsRETklFEe4D9OVqiIi6Yoi3I/ehkBDMyIiQJGE+8DeJQzuW6Keu4hISlGEO8C4Yf3UcxcRSSmacB87tC+19Qc43NRc6FJERAquaMJ93LC+NCecVZt1paqISE7hbmYzzGydmdWa2e0ZXr/NzNaY2etm9qyZnZb/Utt30RkDiYSMP6/ZdrLfWkTklNNhuJtZGJgHzATGAnPNbGyrZsuBanefCDwOfC/fhXakX88oF55ezuLV7+sOkSLS7eXSc58C1Lr7endvBBYAs9MbuPvz7t6QWlwKjMhvmbn52LghbNjZwNvbDxTi7UVEThm5hPtwYFPacl1qXTY3AX88kaI662NjBwPwp9XvF+LtRUROGbmEu2VYl3Hcw8w+A1QD92R5/WYzqzGzmvr6+tyrzNHgvj2YNLI/i1dr3F1Eurdcwr0OGJm2PALY0rqRmU0H7gRmufuRTBty9/nuXu3u1RUVFZ2pt0NXjBvCG5v3smWPHt4hIt1XLuG+DBhjZlVmFgPmAAvTG5jZZOAnJIN9e/7LzN0V4zQ0IyLSYbi7exy4BVgMrAUedffVZna3mc1KNbsH6A08ZmYrzGxhls11udEVvTljUG/+pCmRItKNRXJp5O6LgEWt1t2V9v30PNd1Qq4YN5j7/rqe3QcbGVAaK3Q5IiInXdFcoZpu5vihNCecJ5ZvLnQpIiIFUZThPn54Py6oHMCDL75LvDlR6HJERE66ogx3gC9eOprNew7xtE6sikg3VLThPv2cwVQNLOWnL6zX7QhEpNsp2nAPh4wbL6liZd1eXnl3V6HLERE5qYo23AGuOW8EA3pF+enf3i10KSIiJ1VRh3vPWJjPXljJM2u3Ubt9f6HLERE5aYo63AE+d+Fp9C6J8G9/WKuxdxHpNoo+3Af2LuFr08fw/Lp6nllb0DsjiIicNEUf7gCfv6iSMwf35lu/W61nrIpIt9Atwj0aDnH37PHU7T7E//vLO4UuR0Sky3WLcAeYOrqcWecO476/vsOGHQcLXY6ISJfqNuEOcOfHz6EkEuLWX6+gMa7bEohI8epW4T64bw++96mJrNy0h+8+/WahyxER6TLdKtwBZk4YyhcuquSBF9/VAz1EpGh1u3AHuOPKs5kwvB///bGVbNrVUOhyRETyrluGe0kkzLzrz8OBGx5exu6DjYUuSUQkr7pluAOMKu/FTz9XzcZdDXzh4WUcPBIvdEkiInmTU7ib2QwzW2dmtWZ2e4bXp5nZa2YWN7Nr8l9m15g6upz/O3cyb9Tt4Uv/+apm0IhI0egw3M0sDMwDZgJjgblmNrZVs43AF4BH8l1gV/vYuCF851MT+dvbO/jyL1/lUKOuYBWR4Mul5z4FqHX39e7eCCwAZqc3cPcN7v46EMiu76erR/Ltq8bz7Jvb+ewDL7OnQWPwIhJsuYT7cGBT2nJdat1xM7ObzazGzGrq6+s7s4ku89mppzHv+vN4vW4v1973d7bsOVTokkREOi2XcLcM6zp171x3n+/u1e5eXVFR0ZlNdKkrJwzl4RsvYOvew8yet4SaDXqCk4gEUy7hXgeMTFseAWzpmnIK76LTB/LEly+iNBZmzvyl/GLpe7oPvIgETi7hvgwYY2ZVZhYD5gALu7aswjpzcB+euuUSLh0zkG8+uYqvP7qSfYebCl2WiEjOOgx3d48DtwCLgbXAo+6+2szuNrNZAGZ2gZnVAdcCPzGz1V1Z9MnQr2eUBz5/AbdePoanVm5hxg9e4KXaHYUuS0QkJ1aoIYfq6mqvqakpyHsfr+Ubd/P1R1eyfsdBPjv1NP55xln07REtdFki0g2Z2avuXt1Ru257herxmDxqAH/46qXccHElv3z5PT7y73/lqRWbNRYvIqcshXuOesbC/MsnxvHUVy5hWP8e3LpgBXN/upRVm/cWujQRkTYU7sdpwoh+/PbLF/Ptq8bz1rYD/OOPXuRrC5br7pIickrRmPsJ2He4iZ/89R3u/9u7NCecT543nC/9w+mMruhd6NJEpEjlOuaucM+DrXsP8ZO/rudXr2yksTnBleOHctOlVZw3akChSxORIqNwL4D6/Ud4cMm7/OfS99h/OM6kkf254eJKZo4fSiyiETAROXEK9wI6eCTOb16r46ElG3h3x0HKS2NcWz2SuVNGclp5aaHLE5EAU7ifAhIJ54W363nk5Y08++Z2mhPOlMoyrpo8nI9PGEq/XporLyLHR+F+inl/72F+81odT7xWxzv1B4mFQ1x8Rjkzxg9h+jmDKe9dUugSRSQAFO6nKHdn1eZ9PLViM0+vfp+63YcIWfJCqcvOquCyswdxzpC+hEKZbsYpIt2dwj0A3J01W/exePU2/rJuO6/XJS+IGtg7xkWnD+SSMwYydXQ5I8t6YqawFxGFeyBt33+YF97awZLaHbxYu4P6/UcAGNqvBx+qKuOCqjKqTytjzKDe6tmLdFMK94Bzd97efoCl63fy8ru7eHn9LnYcSIZ93x4RJo0awKQR/Zg4oj8TR/ZjUJ8eBa5YRE4GhXuRcXfe29lAzXu7qdmwixWb9vDWtv0kUodvUJ8Sxg3ry7hh/Th7aB/OHtKXyvJeRMKaXy9STHIN98jJKEZOnJlRObCUyoGlXHP+CAAaGuOs2ryPVZv3smrLXlZv3scLb++gOZX4sUiIMYN6c9aQPpw5uA+V5aVUDuzF8P496V0S0Ti+SBFTuAdYr1iEKVVlTKkqO7ruSLyZ2u0HWLt1P+ve38eb7+/nxbd38MRrm4/52UjI6N8rSu+SCKGQEU4FfWNzgsNNzTQnYHDfEob178nw/j0ZMaDlqxcjy3rRr6fm6HcFd+fhlzawfOMedhw4wq6DjVx29iBu++iZRPUpTI6Dwr3IlETCjBvWj3HD+h2zft/hJjbubGDDzoNs2XOIPQ1N7DnUxIHDcZrdSaR6+yWRECWRMGawbd9hNu5s4O/v7OTAkfgx2+vbI8LIsl70LolQEg0TC4foGQvTKxqmZyz58/FmJ55wIiGjZyxMj0iI0pIIfXtG6dMjwuiBvTlnaB99gkizYNkmvvW7NQzv35Mh/XowoFeMH//lHf7+zk5+NHcyI8t6FbpECYicxtzNbAZwLxAG7nf377R6vQT4OXA+sBO4zt03tLdNjbkHh7uz91ATdbsPsWlXA5t2N7Bp1yE27znEwSNxjsQTHIkne/wNjXEaGpsBiIZDhMxoTiQ43JTgUFNzm21XDSzlyglD+IczB1FZ3ouKPiXdNuzX1x/g4z98kfNPG8DPb5xydEbUH17fyu2/eR0z+PZV45l17rBu+3ckeTyhamZh4C3go0AdyQdmz3X3NWltvgxMdPcvmdkc4Gp3v6697Srcu59Ewmloamb/4Sb2Hmpi+cY9LHpjKy+9s/PoeYIe0RCnlZUyZnBvzhzch6qBpZSVxujXM0q/nlHKSmP0ioWLLtyamhN86scvsXFXA0/fOo0h/Y6d/bRxZwP/bcFyVm7aw0Wnl3P37HGcMahPgaqVQspnuF8I/Ku7X5FavgPA3f93WpvFqTZ/N7MI8D5Q4e1sXOEuLXYeOMLrdXvZtLuBjTsbeHfHQd7avp9Nuw5lbB+LhCjrFWNAaYyy0igDesXoXRKhVyxCaUlyiCgaCREJGdFwiHDIiISMcGo5Ek4uhyz5FQ4f+3o4dQ4inGoTDhnpv0vcwWn7T9swouHkNmKRD943lLa9cMhwh4Q7zQnnwJE4+w418cgrG3loyQbu+8z5zBg/JON+NyecR17ZyD1Pv0lDYzMzxg9hwvB+nDO0LyPLehGLhIiFU1+RD2qQ4pLP2TLDgU1py3XAh7K1cfe4me0FyoEduZUr3Vl57xIuO3tQm/UNjXE27TrEnoZG9h5qYk9DE7sbGtnV0Mjug43sSn1t2bOPg0eSw0EHG+ME9dG211WPzBrsAOGQ8dmpp3Hl+CH8x5/f4i9vbuf3r29td5shg0g4RDTU8kvKCFly9pVB6pdW8pdXy3LylaSWX2rJ1zL/okhf3d4Hqkzbbdsmy/ps75397Y6rUWd+BZ7Ip8dbLx/DJ84d1umfz0Uu4Z5pD1r/98mlDWZ2M3AzwKhRo3J4a+nOesUinDXk+IYePNUjbmp2GpsTNCeceCJBvLllfYKm1PcJ96M96HjqtUQC4onkz33QJtnTbh1Orf/RN7sTb05up7E5QSK13ZZtxRPJE9eh1CeBkBl9ekTo2yM53DR1dHlO+1jeu4T/dfUEAPY0NLJm6z627TtMYzxBY+r8R1OzJ5ebm5M1pE5uuyc/cyTcU59ASP0yTC2n/a9t+XTS0u6Dv+O2bVIL2Y/LMT+fuWG2H8/2yzqX3+G5nFPsVF/gBDsQJ2O2WS7hXgeMTFseAWzJ0qYuNSzTD9jVekPuPh+YD8lhmc4ULNIeM0sOu4ShJ+FCl9Pl+vdK3odIpLVcJs4uA8aYWZWZxYA5wMJWbRYCn099fw3wXHvj7SIi0rU67LmnxtBvARaTnAr5oLuvNrO7gRp3Xwg8APzCzGpJ9tjndGXRIiLSvpwuYnL3RcCiVuvuSvv+MHBtfksTEZHO0vXMIiJFSOEuIlKEFO4iIkVI4S4iUoQU7iIiRahgT2Iys3rgvU7++EC6560NuuN+d8d9hu65391xn+H49/s0d6/oqFHBwv1EmFlNLjfOKTbdcb+74z5D99zv7rjP0HX7rWEZEZEipHAXESlCQQ33+YUuoEC64353x32G7rnf3XGfoYv2O5Bj7iIi0r6g9txFRKQdgQt3M5thZuvMrNbMbi90PV3BzEaa2fNmttbMVpvZran1ZWb2ZzN7O/XngELXmm9mFjaz5Wb2+9RylZm9nNrnX6duO11UzKy/mT1uZm+mjvmF3eRY/1Pq3/cqM/uVmfUotuNtZg+a2XYzW5W2LuOxtaQfprLtdTM770TeO1DhnnpY9zxgJjAWmGtmYwtbVZeIA19393OAqcBXUvt5O/Csu48Bnk0tF5tbgbVpy98FfpDa593ATQWpqmvdCzzt7mcD55Lc/6I+1mY2HPgqUO3u40neTnwOxXe8HwZmtFqX7djOBMakvm4GfnwibxyocAemALXuvt7dG4EFwOwC15R37r7V3V9Lfb+f5H/24ST39WepZj8DripMhV3DzEYAHwfuTy0b8BHg8VSTYtznvsA0ks9EwN0b3X0PRX6sUyJAz9TT23oBWymy4+3uL9D2qXTZju1s4OeetBTob2ZDO/veQQv3TA/rHl6gWk4KM6sEJgMvA4PdfSskfwEAbZ8qHWz/B/gGkEgtlwN73D2eWi7G4z0aqAceSg1H3W9mpRT5sXb3zcC/AxtJhvpe4FWK/3hD9mOb13wLWrjn9CDuYmFmvYHfAF9z932Frqcrmdk/Atvd/dX01RmaFtvxjgDnAT9298nAQYpsCCaT1DjzbKAKGAaUkhyWaK3Yjnd78vrvPWjhnsvDuouCmUVJBvsv3f2J1OptLR/TUn9uL1R9XeBiYJaZbSA53PYRkj35/qmP7VCcx7sOqHP3l1PLj5MM+2I+1gDTgXfdvd7dm4AngIso/uMN2Y9tXvMtaOGey8O6Ay811vwAsNbdv5/2UvqDyD8PPHWya+sq7n6Hu49w90qSx/U5d/8vwPMkH7oORbbPAO7+PrDJzM5KrbocWEMRH+uUjcBUM+uV+vfest9FfbxTsh3bhcDnUrNmpgJ7W4ZvOsXdA/UFXAm8BbwD3FnoerpoHy8h+XHsdWBF6utKkmPQzwJvp/4sK3StXbT/HwZ+n/p+NPAKUAs8BpQUur4u2N9JQE3qeD8JDOgOxxr4FvAmsAr4BVBSbMcb+BXJcwpNJHvmN2U7tiSHZealsu0NkjOflnWzAAAAPklEQVSJOv3eukJVRKQIBW1YRkREcqBwFxEpQgp3EZEipHAXESlCCncRkSKkcBcRKUIKdxGRIqRwFxEpQv8f1q5KtfSkygoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1,1)\n",
    "ax.plot(loss_history, label=\"PyTorch\")\n",
    "ax.legend()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
